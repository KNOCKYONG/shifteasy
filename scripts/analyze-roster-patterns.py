#!/usr/bin/env python3
import pandas as pd
import numpy as np
from collections import defaultdict, Counter
import json
import sys
import os

def analyze_roster_patterns():
    """ì‹¤ì œ ê·¼ë¬´í‘œì—ì„œ íŒ¨í„´ê³¼ ê·œì¹™ì„ ë¶„ì„"""

    # ëª¨ë“  ì—‘ì…€ íŒŒì¼ ì½ê¸°
    all_schedules = []
    nurses_shifts = defaultdict(list)  # ê°„í˜¸ì‚¬ë³„ ê·¼ë¬´ íŒ¨í„´
    shift_patterns = []  # ì „ì²´ ê·¼ë¬´ íŒ¨í„´

    for month in range(1, 10):
        try:
            df = pd.read_excel(f'/Users/nohdol/Downloads/{month}.xls', header=None)

            # ë‚ ì§œ í–‰ ì°¾ê¸° (ë³´í†µ 3ë²ˆì§¸ í–‰)
            date_row = 2
            dates = df.iloc[date_row, 3:34].values  # ìµœëŒ€ 31ì¼

            # ì§ì› ë°ì´í„° ì‹œì‘ í–‰ ì°¾ê¸°
            start_row = None
            for i in range(3, len(df)):
                if pd.notna(df.iloc[i, 0]) and 'ë°•ì„ ë¯¸' in str(df.iloc[i, 1]):
                    start_row = i
                    break

            if start_row:
                month_data = {}
                for i in range(start_row, len(df)):
                    if pd.isna(df.iloc[i, 1]):
                        break

                    name = str(df.iloc[i, 1]).strip()
                    if name and 'í•©ê³„' not in name:
                        shifts = []
                        for j in range(3, min(34, 3 + len(dates))):
                            shift = df.iloc[i, j]
                            if pd.notna(shift):
                                shift_str = str(shift).strip()
                                shifts.append(shift_str)
                                nurses_shifts[name].append(shift_str)

                        month_data[name] = shifts

                all_schedules.append({
                    'month': month,
                    'data': month_data
                })

        except Exception as e:
            print(f"Error reading month {month}: {e}")
            continue

    # ë¶„ì„ ê²°ê³¼
    analysis = {
        'nurses': {},
        'patterns': {},
        'rules': {},
        'statistics': {}
    }

    # 1. ê°„í˜¸ì‚¬ë³„ ê·¼ë¬´ íŒ¨í„´ ë¶„ì„
    for nurse, shifts in nurses_shifts.items():
        shift_counts = Counter(shifts)
        analysis['nurses'][nurse] = {
            'total_shifts': len(shifts),
            'shift_distribution': dict(shift_counts),
            'most_common': shift_counts.most_common(3)
        }

    # 2. ê·¼ë¬´ íŒ¨í„´ ë¶„ì„
    shift_sequences = defaultdict(int)
    consecutive_patterns = defaultdict(int)

    for nurse, shifts in nurses_shifts.items():
        # ì—°ì† ê·¼ë¬´ íŒ¨í„´
        for i in range(len(shifts) - 1):
            pattern = f"{shifts[i]}â†’{shifts[i+1]}"
            shift_sequences[pattern] += 1

        # ì—°ì† ê·¼ë¬´ ì¼ìˆ˜
        consecutive_count = 1
        for i in range(1, len(shifts)):
            if shifts[i] != 'OFF' and shifts[i-1] != 'OFF':
                consecutive_count += 1
            else:
                if consecutive_count > 1:
                    consecutive_patterns[consecutive_count] += 1
                consecutive_count = 1 if shifts[i] != 'OFF' else 0

    analysis['patterns'] = {
        'shift_transitions': dict(sorted(shift_sequences.items(), key=lambda x: x[1], reverse=True)[:20]),
        'consecutive_days': dict(consecutive_patterns)
    }

    # 3. ê·œì¹™ ì¶”ì¶œ
    rules = {
        'hard_constraints': [],
        'soft_constraints': [],
        'discovered_patterns': []
    }

    # í•˜ë“œ ê·œì¹™ ë°œê²¬
    max_consecutive = max(consecutive_patterns.keys()) if consecutive_patterns else 0
    if max_consecutive <= 6:
        rules['hard_constraints'].append(f"ìµœëŒ€ ì—°ì† ê·¼ë¬´: {max_consecutive}ì¼")

    # Night â†’ Day ì „í™˜ íŒ¨í„´ í™•ì¸
    night_to_day = shift_sequences.get('Nâ†’D', 0)
    if night_to_day == 0:
        rules['hard_constraints'].append("Night ê·¼ë¬´ í›„ Day ê·¼ë¬´ ì—†ìŒ")

    # Evening â†’ Day ì „í™˜ íŒ¨í„´
    evening_to_day = shift_sequences.get('Eâ†’D', 0)
    if evening_to_day < 5:  # ê±°ì˜ ì—†ìŒ
        rules['soft_constraints'].append("Evening í›„ Day ê·¼ë¬´ ìµœì†Œí™”")

    # ë¦¬ë” ì—­í•  íŒ¨í„´
    leader_patterns = []
    for pattern, count in shift_sequences.items():
        if 'DL' in pattern or 'EL' in pattern:
            leader_patterns.append((pattern, count))

    if leader_patterns:
        rules['discovered_patterns'].append({
            'type': 'leader_rotation',
            'patterns': leader_patterns[:10]
        })

    analysis['rules'] = rules

    # 4. í†µê³„ ë¶„ì„
    total_shifts = sum(len(shifts) for shifts in nurses_shifts.values())
    unique_shifts = set()
    for shifts in nurses_shifts.values():
        unique_shifts.update(shifts)

    shift_type_counts = Counter()
    for shifts in nurses_shifts.values():
        shift_type_counts.update(shifts)

    analysis['statistics'] = {
        'total_nurses': len(nurses_shifts),
        'total_shifts': total_shifts,
        'unique_shift_types': list(unique_shifts),
        'shift_distribution': dict(shift_type_counts),
        'months_analyzed': len(all_schedules)
    }

    # 5. ì¼ë³„ í•„ìš” ì¸ì› ë¶„ì„
    daily_coverage = defaultdict(lambda: defaultdict(int))

    for schedule in all_schedules:
        month_data = schedule['data']
        # ê° ë‚ ì§œë³„ë¡œ ê·¼ë¬´ ìœ í˜•ë³„ ì¸ì› ê³„ì‚°
        for day_idx in range(31):  # ìµœëŒ€ 31ì¼
            day_shifts = defaultdict(int)
            for nurse, shifts in month_data.items():
                if day_idx < len(shifts):
                    shift = shifts[day_idx]
                    if shift != 'OFF':
                        # ê·¼ë¬´ ìœ í˜• ì •ê·œí™”
                        if shift in ['D', 'DL', '11D']:
                            day_shifts['day'] += 1
                        elif shift in ['E', 'EL']:
                            day_shifts['evening'] += 1
                        elif shift == 'N':
                            day_shifts['night'] += 1

            for shift_type, count in day_shifts.items():
                daily_coverage[shift_type][count] += 1

    # í‰ê·  í•„ìš” ì¸ì› ê³„ì‚°
    coverage_stats = {}
    for shift_type, counts in daily_coverage.items():
        total = sum(counts.values())
        if total > 0:
            weighted_sum = sum(people * freq for people, freq in counts.items())
            coverage_stats[shift_type] = {
                'average': round(weighted_sum / total, 1),
                'min': min(counts.keys()),
                'max': max(counts.keys()),
                'distribution': dict(counts)
            }

    analysis['coverage_requirements'] = coverage_stats

    return analysis

def generate_improvement_recommendations(analysis):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ì œì•ˆ"""

    recommendations = {
        'scheduling_algorithm': [],
        'constraint_optimization': [],
        'fairness_improvements': [],
        'implementation_priority': []
    }

    # 1. ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ ê°œì„ 
    recommendations['scheduling_algorithm'] = [
        {
            'title': 'Pattern-Based Scheduling',
            'description': 'ì‹¤ì œ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ shift transition íŒ¨í„´ì„ í™œìš©',
            'details': [
                f"ìì£¼ ë°œìƒí•˜ëŠ” íŒ¨í„´: {list(analysis['patterns']['shift_transitions'].items())[:5]}",
                "ì´ëŸ¬í•œ íŒ¨í„´ì„ ìš°ì„ ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤ì¼€ì¤„ ìƒì„±"
            ]
        },
        {
            'title': 'Coverage-Driven Assignment',
            'description': 'ì¼ë³„ í•„ìš” ì¸ì›ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í• ë‹¹',
            'details': [
                f"Day shift: í‰ê·  {analysis['coverage_requirements'].get('day', {}).get('average', 0)}ëª…",
                f"Evening shift: í‰ê·  {analysis['coverage_requirements'].get('evening', {}).get('average', 0)}ëª…",
                f"Night shift: í‰ê·  {analysis['coverage_requirements'].get('night', {}).get('average', 0)}ëª…"
            ]
        }
    ]

    # 2. ì œì•½ ì¡°ê±´ ìµœì í™”
    recommendations['constraint_optimization'] = [
        {
            'constraint': 'Max Consecutive Days',
            'current': analysis['patterns']['consecutive_days'],
            'recommendation': 'ìµœëŒ€ 5ì¼ ì—°ì† ê·¼ë¬´ ì œí•œ'
        },
        {
            'constraint': 'Shift Transitions',
            'forbidden': ['Nâ†’D', 'Eâ†’D (minimize)'],
            'preferred': ['Dâ†’E', 'Eâ†’N', 'Nâ†’OFF']
        }
    ]

    # 3. ê³µì •ì„± ê°œì„ 
    nurse_workloads = {}
    for nurse, data in analysis['nurses'].items():
        total = data['total_shifts']
        offs = data['shift_distribution'].get('OFF', 0)
        nurse_workloads[nurse] = total - offs

    avg_workload = np.mean(list(nurse_workloads.values()))
    std_workload = np.std(list(nurse_workloads.values()))

    recommendations['fairness_improvements'] = [
        {
            'metric': 'Workload Distribution',
            'current_std': round(std_workload, 2),
            'target': 'Reduce standard deviation by 30%',
            'method': 'Implement workload balancing algorithm'
        },
        {
            'metric': 'Shift Type Distribution',
            'issue': 'Some nurses have uneven D/E/N distribution',
            'solution': 'Rotate shift types fairly among qualified staff'
        }
    ]

    # 4. êµ¬í˜„ ìš°ì„ ìˆœìœ„
    recommendations['implementation_priority'] = [
        {
            'priority': 1,
            'feature': 'Hard Constraint Enforcement',
            'description': 'í•„ìˆ˜ ê·œì¹™ (ì—°ì† ê·¼ë¬´ ì œí•œ, íœ´ì‹ ì‹œê°„) ìë™ ì ìš©',
            'effort': 'Medium'
        },
        {
            'priority': 2,
            'feature': 'Pattern-Based Generation',
            'description': 'ì‹¤ì œ íŒ¨í„´ì„ í•™ìŠµí•œ ìŠ¤ì¼€ì¤„ ìƒì„± ì•Œê³ ë¦¬ì¦˜',
            'effort': 'High'
        },
        {
            'priority': 3,
            'feature': 'Fairness Optimization',
            'description': 'ê·¼ë¬´ ë¶€ë‹´ ê· ë“± ë¶„ë°° ì‹œìŠ¤í…œ',
            'effort': 'Medium'
        },
        {
            'priority': 4,
            'feature': 'Preference Management',
            'description': 'ê°œì¸ ì„ í˜¸ë„ ë°˜ì˜ ì‹œìŠ¤í…œ',
            'effort': 'Low'
        }
    ]

    return recommendations

# ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ“Š ì‹¤ì œ ê·¼ë¬´í‘œ ë¶„ì„ ì‹œì‘...\n")

    analysis = analyze_roster_patterns()

    print("=" * 60)
    print("ğŸ“‹ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)

    # í†µê³„ ì¶œë ¥
    stats = analysis['statistics']
    print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(f"  - ë¶„ì„ ê¸°ê°„: {stats['months_analyzed']}ê°œì›”")
    print(f"  - ì´ ê°„í˜¸ì‚¬: {stats['total_nurses']}ëª…")
    print(f"  - ê·¼ë¬´ ìœ í˜•: {', '.join(stats['unique_shift_types'])}")

    # íŒ¨í„´ ì¶œë ¥
    print(f"\nğŸ”„ ì£¼ìš” ê·¼ë¬´ ì „í™˜ íŒ¨í„´ (ìƒìœ„ 10ê°œ):")
    for pattern, count in list(analysis['patterns']['shift_transitions'].items())[:10]:
        print(f"  - {pattern}: {count}íšŒ")

    # ì—°ì† ê·¼ë¬´ íŒ¨í„´
    print(f"\nğŸ“… ì—°ì† ê·¼ë¬´ ì¼ìˆ˜ ë¶„í¬:")
    for days, count in sorted(analysis['patterns']['consecutive_days'].items()):
        print(f"  - {days}ì¼ ì—°ì†: {count}íšŒ")

    # ê·œì¹™ ì¶œë ¥
    print(f"\nğŸ“ ë°œê²¬ëœ ê·œì¹™:")
    rules = analysis['rules']
    print("  í•˜ë“œ ì œì•½:")
    for rule in rules['hard_constraints']:
        print(f"    - {rule}")
    print("  ì†Œí”„íŠ¸ ì œì•½:")
    for rule in rules['soft_constraints']:
        print(f"    - {rule}")

    # í•„ìš” ì¸ì› ë¶„ì„
    print(f"\nğŸ‘¥ ì¼ë³„ í•„ìš” ì¸ì›:")
    for shift_type, stats in analysis['coverage_requirements'].items():
        print(f"  - {shift_type}: í‰ê·  {stats['average']}ëª… (ìµœì†Œ {stats['min']}, ìµœëŒ€ {stats['max']})")

    print("\n" + "=" * 60)
    print("ğŸ’¡ ê°œì„  ì œì•ˆ")
    print("=" * 60)

    recommendations = generate_improvement_recommendations(analysis)

    # ì•Œê³ ë¦¬ì¦˜ ê°œì„ 
    print("\nğŸ”§ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ ê°œì„ :")
    for rec in recommendations['scheduling_algorithm']:
        print(f"  [{rec['title']}]")
        print(f"    {rec['description']}")
        for detail in rec['details']:
            print(f"      â€¢ {detail}")

    # êµ¬í˜„ ìš°ì„ ìˆœìœ„
    print("\nğŸ¯ êµ¬í˜„ ìš°ì„ ìˆœìœ„:")
    for item in recommendations['implementation_priority']:
        print(f"  {item['priority']}. {item['feature']} (ë‚œì´ë„: {item['effort']})")
        print(f"     â†’ {item['description']}")

    # JSONìœ¼ë¡œ ì €ì¥
    output = {
        'analysis': analysis,
        'recommendations': recommendations
    }

    with open('/Users/nohdol/project/web_project/shifteasy/scripts/roster_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2, default=str)

    print("\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ roster_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")